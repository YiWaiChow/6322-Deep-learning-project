{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5K2/fq8V4eZKyuSassdTV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### **Import and Model**"],"metadata":{"id":"IOn1Lt81BFRd"}},{"cell_type":"code","source":["!pip install fiftyone\n","!pip install torch torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpiiqfT72Nv9","executionInfo":{"status":"ok","timestamp":1681309848304,"user_tz":240,"elapsed":39284,"user":{"displayName":"Winston Chan","userId":"18037746318607646840"}},"outputId":"893dfec2-5cef-4ed0-a9b7-876f6bfb0635"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fiftyone\n","  Downloading fiftyone-0.20.1-py3-none-any.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hypercorn>=0.13.2\n","  Downloading Hypercorn-0.14.3-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette==0.20.4\n","  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (from fiftyone) (4.7.0.72)\n","Collecting fiftyone-db<0.5,>=0.4\n","  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from fiftyone) (1.2.2)\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.9/dist-packages (from fiftyone) (5.13.1)\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xmltodict\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from fiftyone) (0.18.3)\n","Collecting dacite<1.8.0,>=1.6.0\n","  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n","Collecting Deprecated\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fiftyone) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from fiftyone) (3.7.1)\n","Collecting eventlet\n","  Downloading eventlet-0.33.3-py2.py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from fiftyone) (2022.10.31)\n","Collecting universal-analytics-python3<2,>=1.0.1\n","  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from fiftyone) (6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from fiftyone) (1.5.3)\n","Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.9/dist-packages (from fiftyone) (3.1.2)\n","Collecting retrying\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from fiftyone) (5.3.0)\n","Collecting pymongo>=3.12\n","  Downloading pymongo-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.1/492.1 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fiftyone) (0.8.10)\n","Collecting motor>=2.5\n","  Downloading motor-3.1.2-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from fiftyone) (5.9.4)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from fiftyone) (2022.7.1)\n","Collecting fiftyone-brain<0.12,>=0.11\n","  Downloading fiftyone_brain-0.11.0-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from fiftyone) (67.6.1)\n","Collecting sseclient-py<2,>=1.7.2\n","  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n","Collecting boto3\n","  Downloading boto3-1.26.111-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sse-starlette<1,>=0.10.3\n","  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n","Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.9/dist-packages (from fiftyone) (8.4.0)\n","Collecting argcomplete\n","  Downloading argcomplete-3.0.5-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from fiftyone) (0.19.3)\n","Collecting voxel51-eta<0.10,>=0.9\n","  Downloading voxel51_eta-0.9.0-py2.py3-none-any.whl (568 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pprintpp\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting strawberry-graphql==0.138.1\n","  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mongoengine==0.24.2\n","  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from fiftyone) (23.0)\n","Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from starlette==0.20.4->fiftyone) (4.5.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette==0.20.4->fiftyone) (3.6.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.9/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n","Collecting graphql-core<3.3.0,>=3.2.0\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from fiftyone-brain<0.12,>=0.11->fiftyone) (1.10.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n","Collecting priority\n","  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n","Collecting h2>=3.1.0\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wsproto>=0.14.0\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3->fiftyone) (2.1.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=4.14->fiftyone) (8.2.2)\n","Collecting dnspython<3.0.0,>=1.16.0\n","  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.10.0\n","  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rarfile\n","  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (2.27.1)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (0.7)\n","Collecting dill\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (1.16.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (1.26.15)\n","Collecting py7zr\n","  Downloading py7zr-0.20.4-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (2.4.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.9/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (4.3)\n","Collecting jsonlines\n","  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n","Collecting botocore<1.30.0,>=1.29.111\n","  Downloading botocore-1.29.111-py3-none-any.whl (10.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from Deprecated->fiftyone) (1.14.1)\n","Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.9/dist-packages (from eventlet->fiftyone) (2.0.2)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->fiftyone) (0.2.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (4.39.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (5.12.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fiftyone) (1.0.7)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->fiftyone) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->fiftyone) (2023.3.21)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->fiftyone) (1.4.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->fiftyone) (3.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (1.3.0)\n","Collecting hyperframe<7,>=6.0\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack<5,>=4.0\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.12.7)\n","Collecting httpcore<0.18.0,>=0.15.0\n","  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->fiftyone) (3.15.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from jsonlines->voxel51-eta<0.10,>=0.9->fiftyone) (22.2.0)\n","Collecting multivolumefile>=0.2.3\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting brotli>=1.0.9\n","  Downloading Brotli-1.0.9-cp39-cp39-manylinux1_x86_64.whl (357 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n","  Downloading pyppmd-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.14.4\n","  Downloading pyzstd-0.15.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.4/390.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj>=0.6.0\n","  Downloading pybcj-1.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting inflate64>=0.3.1\n","  Downloading inflate64-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycryptodomex>=3.6.6\n","  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting texttable\n","  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->voxel51-eta<0.10,>=0.9->fiftyone) (2.0.12)\n","Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.9/dist-packages (from tzlocal->voxel51-eta<0.10,>=0.9->fiftyone) (0.1.0.post0)\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.9/dist-packages (from pytz-deprecation-shim->tzlocal->voxel51-eta<0.10,>=0.9->fiftyone) (2023.3)\n","Installing collected packages: texttable, sseclient-py, rarfile, pprintpp, kaleido, brotli, xmltodict, retrying, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, eventlet, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n","Successfully installed Deprecated-1.2.13 aiofiles-23.1.0 argcomplete-3.0.5 boto3-1.26.111 botocore-1.29.111 brotli-1.0.9 dacite-1.7.0 dill-0.3.6 dnspython-2.3.0 eventlet-0.33.3 fiftyone-0.20.1 fiftyone-brain-0.11.0 fiftyone-db-0.4.0 ftfy-6.1.1 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.0 httpx-0.24.0 hypercorn-0.14.3 hyperframe-6.0.1 inflate64-0.3.1 jmespath-1.0.1 jsonlines-3.1.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.1.2 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.4 pybcj-1.0.1 pycryptodomex-3.17 pymongo-4.3.3 pyppmd-1.0.0 pyzstd-0.15.6 rarfile-4.0 retrying-1.3.4 s3transfer-0.6.0 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.20.4 strawberry-graphql-0.138.1 texttable-1.6.7 universal-analytics-python3-1.1.1 voxel51-eta-0.9.0 wsproto-1.2.0 xmltodict-0.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision\n","\n","%%shell\n","\n","# Download TorchVision repo to use some files from\n","# references/detection\n","git clone https://github.com/pytorch/vision.git\n","cd vision\n","git checkout v0.3.0\n","\n","cp references/detection/utils.py ../\n","cp references/detection/transforms.py ../\n","cp references/detection/coco_eval.py ../\n","cp references/detection/engine.py ../\n","cp references/detection/coco_utils.py ../"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPI2r_-KGZIz","executionInfo":{"status":"ok","timestamp":1681309948488,"user_tz":240,"elapsed":93996,"user":{"displayName":"Winston Chan","userId":"18037746318607646840"}},"outputId":"f3bc6346-7915-4212-842a-5e5af9e06d51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'vision'...\n","remote: Enumerating objects: 322010, done.\u001b[K\n","remote: Counting objects: 100% (5032/5032), done.\u001b[K\n","remote: Compressing objects: 100% (583/583), done.\u001b[K\n","remote: Total 322010 (delta 4603), reused 4833 (delta 4440), pack-reused 316978\u001b[K\n","Receiving objects: 100% (322010/322010), 652.22 MiB | 21.07 MiB/s, done.\n","Resolving deltas: 100% (295977/295977), done.\n","Note: switching to 'v0.3.0'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at be376084d8 version check against PyTorch's CUDA version\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHXxjz2JCFM9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681310091114,"user_tz":240,"elapsed":2148,"user":{"displayName":"Winston Chan","userId":"18037746318607646840"}},"outputId":"a8d45fc7-ee67-4626-e173-735dd8f6f79e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch._six (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch._six\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["import torch\n","from torch.utils.data import Dataset\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","import utils\n","import torch.nn as nn\n","from torchvision.transforms import ToTensor"]},{"cell_type":"code","source":["class Patch_Embedding(nn.Module):\n","    def __init__(self, channel, embed_dim, patch_dim):\n","        super().__init__()\n","        self.in_dim = channel\n","        self.out_dim = embed_dim\n","\n","        self.P = patch_dim\n","\n","        # this outputs a shape of Batch size, embedding dimension, H, W\n","        self.linear = nn.Conv2d(\n","            channel, embed_dim, kernel_size=patch_dim, stride=patch_dim, bias=True)\n","        # self.norm = nn.LayerNorm([height/self.P, width/self.P, embed_dim])\n","        self.norm = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","\n","        # flatten it into 2d, so H and W collapse into number of patches, then we swap the shape\n","        # from [B, ED, H,W] -> [B, ED, number of patches] -> [B, number of patches, ED]\n","        # this is done to follow the convention of the paper, where the embedding dimension is the last dimension\n","\n","        x = self.linear(x)\n","\n","        x = x.flatten(2).transpose(1, 2)\n","        x = self.norm(x)\n","        # output shape should be [B, Number of patches, ED], where number of patches should be HW/4*2\n","\n","        return x\n","\n","\n","# Spatial-Reduction Attention\n","class SRAttention(nn.Module):\n","    def __init__(self, num_heads, channels, height, width, reduction_ratio, batch_size):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.head_dimension = channels//self.num_heads\n","\n","        self.c = channels\n","\n","        # the Weight is Ci X d Head, so the input dimension should be c and the output should be d head\n","        self.L = nn.Linear(self.c,\n","                           self.head_dimension)\n","        self.sr = SR(height, width, channels,\n","                     reduction_ratio, batch_size)\n","        #  Wo has size Ci X Ci, this is becasuse d head = Ci/Ni, after concatnating N Ci, the dimension becomes Ci.\n","        self.L2 = nn.Linear(self.c, self.c)\n","\n","    def forward(self, query, key, value):\n","        SRA = None\n","        for i in range(self.num_heads):\n","            # HW x d_head\n","            qi = self.L(query)\n","            # HW/R^2 x d_head\n","            srk = self.L(self.sr(key))\n","            # HW/R^2 x d_head\n","            srv = self.L(self.sr(value))\n","            # attention at stage i\n","            # HW X d_head @ d_head X HW/R^2 @ HW/R^2 x d_head = > HW X d_head <--- the shape of the A_i\n","            Ai = ((torch.softmax(qi.clone().detach()@srk.clone().detach().transpose(1, 2) /\n","                                (self.head_dimension**0.5), dim=1))@srv)\n","            if(SRA is None):\n","                SRA = Ai\n","            else:\n","\n","                SRA = torch.cat((SRA, Ai), dim=2)\n","\n","        # SRA after concatinating should be HW X D_head*Ni -> HW X Ci\n","        SRA = self.L2(SRA)\n","\n","        return SRA\n","\n","\n","# Spatial Reduction\n","# SR(x) = Norm(Reshape(x,Ri)W^s)\n","class SR(nn.Module):\n","    def __init__(self, height, width, channels, reduction_ratio, batch_size):\n","        super().__init__()\n","        self.H = height\n","        self.W = width\n","        self.C = channels\n","        self.B = batch_size\n","        self.R = reduction_ratio\n","        # after reshaping x into HW/R^2 X R^2C, it takes in R^2C and projects to Ci\n","        self.linear_projection = nn.Linear(self.R**2*self.C, self.C)\n","        # then re layer norm on the number of channels\n","        self.norm = nn.LayerNorm(self.C)\n","\n","    def forward(self, x):\n","        # reduced the sptial scale of x\n","        # by reshaping the sequence into size HW/R^2 X R^2C at stage i\n","\n","        reduced_x = torch.reshape(\n","            x, [self.B, self.H*self.W//(self.R**2), (self.R**2*self.C)]).clone()\n","        new_x = self.linear_projection(reduced_x)\n","        new_x = self.norm(new_x)\n","        # output should be of size HW/R^2 x CI\n","\n","        return new_x\n","\n","\n","class Feed_Forward(nn.Module):\n","    def __init__(self, in_size, hidden_size, out_size):\n","        super().__init__()\n","        self.l1 = nn.Linear(in_size, hidden_size)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.l2 = nn.Linear(hidden_size, out_size)\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = self.relu(x)\n","        x = self.l2(x)\n","        return x\n","\n","\n","class Transformer_Encoder(nn.Module):\n","    def __init__(self, height, width, channels, reduction_ratio, patch_dim, batch_size, num_heads):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.norm1 = nn.LayerNorm(channels)\n","        self.a = SRAttention(self.num_heads, channels,\n","                             height//patch_dim, width//patch_dim, reduction_ratio, batch_size)\n","        self.norm2 = nn.LayerNorm(channels)\n","        self.ff = Feed_Forward(channels, channels//2, channels)\n","\n","    def forward(self, x):\n","        n1 = self.norm1(x)\n","        a = self.a(n1, n1, n1)\n","        x1 = torch.add(x, a)\n","        n2 = self.norm2(x1)\n","        ff = self.ff(n2)\n","        x2 = torch.add(x1, ff)\n","        return x2\n","\n","\n","class Stage_Module(nn.Module):\n","    # # # added parameter patch_dim\n","    def __init__(self, channels, embedding_dim, Height, Width, reduction_ratio, patch_dim, batch_size, num_heads):\n","        super().__init__()\n","        self.H = Height\n","        self.W = Width\n","        self.out_dim = embedding_dim\n","        self.P = patch_dim\n","        self.B = batch_size\n","        self.PE = Patch_Embedding(channels, embedding_dim, patch_dim)\n","        self.TE = Transformer_Encoder(\n","            Height, Width, embedding_dim, reduction_ratio, patch_dim, batch_size, num_heads)\n","\n","    def forward(self, x):\n","        x = self.PE(x)\n","        x = self.TE(x)\n","        # # # reshape to H(i-1)/P x W(i-1)/P x ED as output\n","        x = torch.reshape(x.clone(), [self.B, self.H//self.P,\n","                              self.W//self.P, self.out_dim]).permute([0, 3, 1, 2])\n","        return x\n","\n","\n","class PVT(nn.Module):\n","    def __init__(self, channels, height, width, batch_size):\n","        super().__init__()\n","        # input at stage 1 is H X W X 3\n","\n","        self.stg1 = Stage_Module(channels, 64, height,\n","                                 width, reduction_ratio=8, patch_dim=4, batch_size=batch_size, num_heads=1)\n","        \n","        self.stg2 = Stage_Module(\n","            64, 128, height//4, width//4, reduction_ratio=4, patch_dim=2, batch_size=batch_size, num_heads=2)\n","        \n","        self.stg3 = Stage_Module(\n","            128, 256, height//8, width//8, reduction_ratio=2, patch_dim=2, batch_size=batch_size, num_heads=4)\n","        \n","        self.stg4 = Stage_Module(256, 512, height//16,\n","                                 width//16, reduction_ratio=1, patch_dim=2, batch_size=batch_size, num_heads=8)\n","        \n","\n","        self.head = nn.linear(512)\n","\n","    def forward(self, x):\n","\n","        x = self.stg1(x)\n","\n","        x = self.stg2(x)\n","\n","        x = self.stg3(x)\n","\n","        x = self.stg4(x)\n","\n","        return x\n","\n","\n","class classification_pvt(nn.Module):\n","    def __init__(self, channels, height, width, batch_size, num_classes):\n","        super().__init__()\n","        # input at stage 1 is H X W X 3\n","\n","        # # # will look to clean it up later\n","        # # # maybe we should only pass the original height and width for all stages, will verify it tmr\n","        self.stg1 = Stage_Module(channels, 64, height,\n","                                 width, reduction_ratio=8, patch_dim=4, batch_size=batch_size, num_heads=1)\n","        self.stg2 = Stage_Module(\n","            64, 128, height//4, width//4, reduction_ratio=4, patch_dim=2, batch_size=batch_size, num_heads=2)\n","        self.stg3 = Stage_Module(\n","            128, 256, height//8, width//8, reduction_ratio=2, patch_dim=2, batch_size=batch_size, num_heads=4)\n","        self.stg4 = Stage_Module(256, 512, height//16,\n","                                 width//16, reduction_ratio=1, patch_dim=2, batch_size=batch_size, num_heads=8)\n","\n","        self.head = nn.Linear(7*7*512, 128)\n","        self.head2 = nn.Linear(128, num_classes)\n","        self.relu = nn.ReLU(inplace=False)\n","\n","    def forward(self, x):\n","\n","        x = self.stg1(x)\n","\n","        x = self.stg2(x)\n","\n","        x = self.stg3(x)\n","\n","        x = self.stg4(x).permute([0, 2, 3, 1])\n","        \n","        x = x.contiguous().view(-1, 7*7*512)\n","        x = self.head(x)\n","        x = self.relu(x)\n","        x = self.head2(x)\n","        return x\n","\n","class detection_pvt(nn.Module):\n","    def __init__(self, channels, height, width, batch_size, num_classes):\n","        super().__init__()\n","        # input at stage 1 is H X W X 3\n","\n","        self.stg1 = Stage_Module(channels, 64, height,\n","                                 width, reduction_ratio=8, patch_dim=4, batch_size=batch_size, num_heads=1)\n","        self.stg2 = Stage_Module(\n","            64, 128, height//4, width//4, reduction_ratio=4, patch_dim=2, batch_size=batch_size, num_heads=2)\n","        self.stg3 = Stage_Module(\n","            128, 256, height//8, width//8, reduction_ratio=2, patch_dim=2, batch_size=batch_size, num_heads=4)\n","        self.stg4 = Stage_Module(256, 512, height//16,\n","                                 width//16, reduction_ratio=1, patch_dim=2, batch_size=batch_size, num_heads=8)\n","\n","        self.head = nn.Linear(20*15*512, 128)\n","        self.label = nn.Linear(128, num_classes)\n","        self.box = nn.Linear(128, 4)\n","        self.relu = nn.ReLU(inplace=False)\n","\n","    def forward(self, x):\n","\n","        x = self.stg1(x)\n","\n","        x = self.stg2(x)\n","\n","        x = self.stg3(x)\n","\n","        x = self.stg4(x).permute([0, 2, 3, 1])\n","        \n","        x = x.contiguous().view(-1, 20*15*512)\n","        x = self.head(x)\n","        x = self.relu(x)\n","        label = self.label(x)\n","        box = self.box(x)\n","        return label, box"],"metadata":{"id":"L7AWGZyzCyBE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **COCO2017 (detection)**"],"metadata":{"id":"i1Pa931rBMQd"}},{"cell_type":"code","source":["import fiftyone.utils.coco as fouc\n","import fiftyone.zoo as foz\n","import fiftyone as fo\n","from PIL import Image\n","\n","\n","class FiftyOneTorchDataset(torch.utils.data.Dataset):\n","    def __init__(\n","        self,\n","        fiftyone_dataset,\n","        transforms=None,\n","        gt_field=\"ground_truth\",\n","        classes=None,\n","    ):\n","        self.samples = fiftyone_dataset\n","        self.transforms = transforms\n","        self.gt_field = gt_field\n","\n","        self.img_paths = self.samples.values(\"filepath\")\n","\n","        self.classes = classes\n","        if not self.classes:\n","            self.classes = self.samples.distinct(\n","                \"%s.detections.label\" % gt_field\n","            )\n","\n","        if self.classes[0] != \"background\":\n","            self.classes = [\"background\"] + self.classes\n","\n","        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_paths[idx]\n","        sample = self.samples[img_path]\n","        metadata = sample.metadata\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        boxes = []\n","        labels = []\n","        area = []\n","        iscrowd = []\n","        detections = sample[self.gt_field].detections\n","        for det in detections:\n","            category_id = self.labels_map_rev[det.label]\n","            coco_obj = fouc.COCOObject.from_label(\n","                det, metadata, category_id=category_id,\n","            )\n","            x, y, w, h = coco_obj.bbox\n","            boxes.append([x, y, x + w, y + h])\n","            labels.append(coco_obj.category_id)\n","            area.append(coco_obj.area)\n","            iscrowd.append(coco_obj.iscrowd)\n","\n","        target = {}\n","        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n","        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n","        target[\"image_id\"] = torch.as_tensor([idx])\n","        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n","        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n","\n","        if self.transforms is not None:\n","            img, target = self.transforms(img, target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def get_classes(self):\n","        return self.classes"],"metadata":{"id":"qpsHFKG19FAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["coco_train = foz.load_zoo_dataset(\n","    \"coco-2017\",\n","    split = \"train\",\n","    label_types=[\"detections\"],\n","    max_samples = 1000)\n","\n","# coco_val = foz.load_zoo_dataset(\n","#     \"coco-2017\",\n","#     split = \"validation\",\n","#     label_types=[\"detections\"])"],"metadata":{"id":"cZE5rAwU9yVC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681310604895,"user_tz":240,"elapsed":42616,"user":{"displayName":"Winston Chan","userId":"18037746318607646840"}},"outputId":"d2490801-459f-4089-8bd7-cc8ac20c211c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"output_type":"stream","name":"stdout","text":["Found annotations at '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"output_type":"stream","name":"stdout","text":["Sufficient images already downloaded\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"]},{"output_type":"stream","name":"stdout","text":["Existing download of split 'train' is sufficient\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Existing download of split 'train' is sufficient\n"]},{"output_type":"stream","name":"stdout","text":["Loading existing dataset 'coco-2017-train-1000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Loading existing dataset 'coco-2017-train-1000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"]}]},{"cell_type":"code","source":["coco_train.compute_metadata()\n","#coco_val.compute_metadata()\n","\n","batch_size = 16\n","\n","train_transforms = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(0.5)])\n","test_transforms = transforms.Compose([transforms.ToTensor()])\n","\n","torch_dataset = FiftyOneTorchDataset(coco_train, train_transforms)\n","\n","torch_dataset_test = FiftyOneTorchDataset(coco_train, test_transforms)\n","\n","data_loader = torch.utils.data.DataLoader(\n","        torch_dataset, batch_size=batch_size,\n","        shuffle=True, num_workers=2,\n","        collate_fn=utils.collate_fn)\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","        torch_dataset_test, batch_size=batch_size,\n","        shuffle=False, num_workers=2,\n","        collate_fn=utils.collate_fn)"],"metadata":{"id":"np_zybomBt9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","net = detection_pvt(3, 640, 480, batch_size, 80)\n","net.to(device)\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.005,\n","                                momentum=0.9, weight_decay=0.0005)\n","\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                    step_size=3,\n","                                                    gamma=0.1)\n"],"metadata":{"id":"vSxG2MuUCYAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" for epoch in range(30):\n","        # train for one epoch, printing every 10 iterations\n","        train_one_epoch(net, optimizer, data_loader, device, epoch, print_freq=10)\n","\n","        # update the learning rate\n","        lr_scheduler.step()\n","        # evaluate on the test dataset\n","        evaluate(model, data_loader_test, device=device)"],"metadata":{"id":"PapWGAZK7OX6"},"execution_count":null,"outputs":[]}]}