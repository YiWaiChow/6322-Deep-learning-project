{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgbjl83AdvV"
      },
      "source": [
        "### **Import and Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrFgisLjAZcj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import ToTensor\n",
        "from model import classification_pvt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Zkmyf-A6NX"
      },
      "source": [
        "### **CIFAR100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd7BOvkpA377"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsZlhujAA73J"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "net = classification_pvt(3, 224, 224, batch_size, 100)\n",
        "net.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=5e-5, betas=[0.9, 0.999], weight_decay=1e-8)\n",
        "#optimizer = optim.AdamW(net.parameters(), lr=1e-3, betas=[0.9, 0.999], weight_decay=5e-2) # hyperparameters specified in the paper\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y69P5uQPA9C1"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "los4qODoA90Y"
      },
      "outputs": [],
      "source": [
        "save_path = '../ckpt_cifar100/'\n",
        "\n",
        "for epoch in range(100):\n",
        "    loss_train = 0.0\n",
        "    correct_pred = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = net(images)\n",
        "        loss = loss_fn(pred, labels)\n",
        "        torch.autograd.set_detect_anomaly(True) # for debugging\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      torch.save(net.state_dict(), save_path + f'{epoch+1}.pth')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            pred = net(images)\n",
        "            _, predictions = torch.max(pred.data, 1)\n",
        "            correct_pred += (predictions == labels).sum().item()\n",
        "    \n",
        "    print(f'Epoch {epoch + 1} -- loss: {loss_train/(50000//batch_size)}')\n",
        "    print(f'---------- testing accuracy: {correct_pred/(batch_size*(10000//batch_size))}')\n",
        "    print('#################################################')\n",
        "\n",
        "print('Training completed')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
